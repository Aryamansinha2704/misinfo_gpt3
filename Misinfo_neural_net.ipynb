{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>statement_originator</th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_date</th>\n",
       "      <th>statement_source</th>\n",
       "      <th>factchecker</th>\n",
       "      <th>factcheck_date</th>\n",
       "      <th>factcheck_analysis_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>John McCain opposed bankruptcy protections for...</td>\n",
       "      <td>6/11/2008</td>\n",
       "      <td>speech</td>\n",
       "      <td>Adriel Bettelheim</td>\n",
       "      <td>6/16/2008</td>\n",
       "      <td>https://www.politifact.com/factchecks/2008/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>Matt Gaetz</td>\n",
       "      <td>\"Bennie Thompson actively cheer-led riots in t...</td>\n",
       "      <td>6/7/2022</td>\n",
       "      <td>television</td>\n",
       "      <td>Yacob Reyes</td>\n",
       "      <td>6/13/2022</td>\n",
       "      <td>https://www.politifact.com/factchecks/2022/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Kelly Ayotte</td>\n",
       "      <td>Says Maggie Hassan was \"out of state on 30 day...</td>\n",
       "      <td>5/18/2016</td>\n",
       "      <td>news</td>\n",
       "      <td>Clay Wirestone</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>https://www.politifact.com/factchecks/2016/may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"BUSTED: CDC Inflated COVID Numbers, Accused o...</td>\n",
       "      <td>2/1/2021</td>\n",
       "      <td>blog</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>https://www.politifact.com/factchecks/2021/feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Bobby Jindal</td>\n",
       "      <td>\"I'm the only (Republican) candidate that has ...</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>television</td>\n",
       "      <td>Linda Qiu</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>https://www.politifact.com/factchecks/2015/aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21147</th>\n",
       "      <td>mostly-false</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Says the large trade deficit with Japan stems ...</td>\n",
       "      <td>8/13/2019</td>\n",
       "      <td>speech</td>\n",
       "      <td>Jon Greenberg</td>\n",
       "      <td>8/15/2019</td>\n",
       "      <td>https://www.politifact.com/factchecks/2019/aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21148</th>\n",
       "      <td>false</td>\n",
       "      <td>Donald Trump Jr.</td>\n",
       "      <td>\"Tens of thousands\" of people leave New York e...</td>\n",
       "      <td>11/1/2019</td>\n",
       "      <td>social_media</td>\n",
       "      <td>Jill Terreri Ramos</td>\n",
       "      <td>11/8/2019</td>\n",
       "      <td>https://www.politifact.com/factchecks/2019/nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21149</th>\n",
       "      <td>mostly-false</td>\n",
       "      <td>Chris Abele</td>\n",
       "      <td>\"I have fought for our shared values without b...</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>news</td>\n",
       "      <td>Dave Umhoefer</td>\n",
       "      <td>1/13/2011</td>\n",
       "      <td>https://www.politifact.com/factchecks/2011/jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21150</th>\n",
       "      <td>false</td>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"Germany halts all Covid-19 vaccines, says the...</td>\n",
       "      <td>8/27/2021</td>\n",
       "      <td>blog</td>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>9/9/2021</td>\n",
       "      <td>https://www.politifact.com/factchecks/2021/sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21151</th>\n",
       "      <td>mostly-false</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Says for otherwise healthy people \"experiencin...</td>\n",
       "      <td>3/28/2020</td>\n",
       "      <td>social_media</td>\n",
       "      <td>Tom Kertscher</td>\n",
       "      <td>4/3/2020</td>\n",
       "      <td>https://www.politifact.com/factchecks/2020/apr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21152 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            verdict statement_originator  \\\n",
       "0              true         Barack Obama   \n",
       "1             false           Matt Gaetz   \n",
       "2       mostly-true         Kelly Ayotte   \n",
       "3             false             Bloggers   \n",
       "4         half-true         Bobby Jindal   \n",
       "...             ...                  ...   \n",
       "21147  mostly-false         Donald Trump   \n",
       "21148         false     Donald Trump Jr.   \n",
       "21149  mostly-false          Chris Abele   \n",
       "21150         false             Bloggers   \n",
       "21151  mostly-false       Facebook posts   \n",
       "\n",
       "                                               statement statement_date  \\\n",
       "0      John McCain opposed bankruptcy protections for...      6/11/2008   \n",
       "1      \"Bennie Thompson actively cheer-led riots in t...       6/7/2022   \n",
       "2      Says Maggie Hassan was \"out of state on 30 day...      5/18/2016   \n",
       "3      \"BUSTED: CDC Inflated COVID Numbers, Accused o...       2/1/2021   \n",
       "4      \"I'm the only (Republican) candidate that has ...      8/30/2015   \n",
       "...                                                  ...            ...   \n",
       "21147  Says the large trade deficit with Japan stems ...      8/13/2019   \n",
       "21148  \"Tens of thousands\" of people leave New York e...      11/1/2019   \n",
       "21149  \"I have fought for our shared values without b...       1/4/2011   \n",
       "21150  \"Germany halts all Covid-19 vaccines, says the...      8/27/2021   \n",
       "21151  Says for otherwise healthy people \"experiencin...      3/28/2020   \n",
       "\n",
       "      statement_source         factchecker factcheck_date  \\\n",
       "0               speech   Adriel Bettelheim      6/16/2008   \n",
       "1           television         Yacob Reyes      6/13/2022   \n",
       "2                 news      Clay Wirestone      5/27/2016   \n",
       "3                 blog      Madison Czopek       2/5/2021   \n",
       "4           television           Linda Qiu      8/30/2015   \n",
       "...                ...                 ...            ...   \n",
       "21147           speech       Jon Greenberg      8/15/2019   \n",
       "21148     social_media  Jill Terreri Ramos      11/8/2019   \n",
       "21149             news       Dave Umhoefer      1/13/2011   \n",
       "21150             blog      Ciara O'Rourke       9/9/2021   \n",
       "21151     social_media       Tom Kertscher       4/3/2020   \n",
       "\n",
       "                                 factcheck_analysis_link  \n",
       "0      https://www.politifact.com/factchecks/2008/jun...  \n",
       "1      https://www.politifact.com/factchecks/2022/jun...  \n",
       "2      https://www.politifact.com/factchecks/2016/may...  \n",
       "3      https://www.politifact.com/factchecks/2021/feb...  \n",
       "4      https://www.politifact.com/factchecks/2015/aug...  \n",
       "...                                                  ...  \n",
       "21147  https://www.politifact.com/factchecks/2019/aug...  \n",
       "21148  https://www.politifact.com/factchecks/2019/nov...  \n",
       "21149  https://www.politifact.com/factchecks/2011/jan...  \n",
       "21150  https://www.politifact.com/factchecks/2021/sep...  \n",
       "21151  https://www.politifact.com/factchecks/2020/apr...  \n",
       "\n",
       "[21152 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('Downloads/politifact_factcheck_data.json', lines=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['statement_month'] = pd.to_datetime(data['statement_date']).dt.month\n",
    "data['statement_year'] = pd.to_datetime(data['statement_date']).dt.year\n",
    "data['factcheck_month'] = pd.to_datetime(data['factcheck_date']).dt.month\n",
    "data['factcheck_year'] = pd.to_datetime(data['factcheck_date']).dt.year\n",
    "data = data.drop(['statement_date', 'factcheck_date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false           5625\n",
       "half-true       3597\n",
       "mostly-false    3432\n",
       "mostly-true     3332\n",
       "pants-fire      2703\n",
       "true            2463\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verdict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verdict_cleaner(verdict):\n",
    "    if verdict == \"mostly-true\":\n",
    "        return True\n",
    "    elif verdict == \"mostly-false\":\n",
    "        return False\n",
    "    elif verdict == \"pants-fire\":\n",
    "        return False\n",
    "    elif verdict == \"half-true\":\n",
    "        return True\n",
    "    elif verdict == \"true\":\n",
    "        return True\n",
    "    elif verdict == \"false\":\n",
    "        return False\n",
    "data['verdict'] = data['verdict'].apply(lambda x: verdict_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['statement_originator', 'statement_source', 'factchecker', 'statement_month', 'statement_year', 'factcheck_month', 'factcheck_year']\n",
    "X = data[features][:gpt_labels.size]\n",
    "y = data['verdict'].to_numpy()[:gpt_labels.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamansinha/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,), solver='lbfgs')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns = features).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02006576, -0.00168578, -0.02763794, ..., -0.02205827,\n",
       "         -0.03367699,  0.02568597],\n",
       "        [-0.0270251 , -0.00232394, -0.00242388, ..., -0.02984008,\n",
       "          0.00576328,  0.0097319 ],\n",
       "        [ 0.07297819,  0.12770793,  0.14547976, ...,  0.05376882,\n",
       "         -0.02337113, -0.00825092],\n",
       "        ...,\n",
       "        [ 0.05953523,  0.57798697, -1.19289254, ...,  0.08613265,\n",
       "          0.03116958,  0.26115091],\n",
       "        [ 0.23309602,  0.60212458,  0.34645248, ..., -0.74435919,\n",
       "         -0.10915374, -0.83851165],\n",
       "        [-0.3310556 , -0.49906313,  0.01534623, ...,  0.25558392,\n",
       "          0.01172932,  0.02280451]]), array([[ 7.05303712],\n",
       "        [ 6.64103525],\n",
       "        [ 5.87190094],\n",
       "        [-0.95851829],\n",
       "        [-3.84137772],\n",
       "        [-4.78449441],\n",
       "        [-5.73583833],\n",
       "        [ 2.59961356],\n",
       "        [-4.41170045],\n",
       "        [ 0.51681217],\n",
       "        [-5.39789371],\n",
       "        [-2.55537446],\n",
       "        [ 8.45976051],\n",
       "        [ 1.29297138],\n",
       "        [ 3.47177661]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.66441623,  0.20165708, -0.00965081,  0.06184447,  0.70666166,\n",
       "         0.08768057, -0.07707376,  1.23139407,  0.61924861, -0.13129165,\n",
       "        -0.70085283, -0.65181311, -0.57934973, -0.19073765, -0.18667326]),\n",
       " array([1.62036359])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logistic'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'solver': ['lbfgs', 'sgd'], 'hidden_layer_sizes':[(15,), (5,), (10,)], 'alpha': [1e-4, 1e-5, 1e-6]}\n",
    "]\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring = 'precision')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826738</td>\n",
       "      <td>0.208688</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (15,),...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.522212</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.786520</td>\n",
       "      <td>0.043081</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (15,),...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.621905</td>\n",
       "      <td>0.070574</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811721</td>\n",
       "      <td>0.354861</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (5,), ...</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578873</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.392302</td>\n",
       "      <td>0.096564</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (5,), ...</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518784</td>\n",
       "      <td>0.271319</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.400955</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.539876</td>\n",
       "      <td>0.046910</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.323489</td>\n",
       "      <td>0.265982</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.606205</td>\n",
       "      <td>0.073224</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.873862</td>\n",
       "      <td>0.078980</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (15,), ...</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.533250</td>\n",
       "      <td>0.036483</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.656241</td>\n",
       "      <td>1.110400</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (15,), ...</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.624090</td>\n",
       "      <td>0.099133</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.687885</td>\n",
       "      <td>0.755351</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (5,), '...</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.542935</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.650121</td>\n",
       "      <td>1.107171</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (5,), '...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.085128</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.133727</td>\n",
       "      <td>0.225058</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (10,), ...</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.548204</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.743411</td>\n",
       "      <td>0.238099</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'hidden_layer_sizes': (10,), ...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.581715</td>\n",
       "      <td>0.046571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.833095</td>\n",
       "      <td>0.078432</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (15,), ...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.558005</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.737202</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (15,), ...</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.583826</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.135623</td>\n",
       "      <td>0.382506</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (5,), '...</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.528530</td>\n",
       "      <td>0.022078</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.272423</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (5,), '...</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261212</td>\n",
       "      <td>0.320161</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.480208</td>\n",
       "      <td>1.164858</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (10,), ...</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.552287</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.773138</td>\n",
       "      <td>1.677395</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-06, 'hidden_layer_sizes': (10,), ...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.679303</td>\n",
       "      <td>0.127166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.826738      0.208688         0.004993        0.000248      0.0001   \n",
       "1        3.786520      0.043081         0.002978        0.000342      0.0001   \n",
       "2        0.811721      0.354861         0.002962        0.000282      0.0001   \n",
       "3        2.392302      0.096564         0.003941        0.000315      0.0001   \n",
       "4        0.990354      0.400955         0.003253        0.000207      0.0001   \n",
       "5        3.323489      0.265982         0.003442        0.000398      0.0001   \n",
       "6        0.873862      0.078980         0.005329        0.000283     0.00001   \n",
       "7        5.656241      1.110400         0.004690        0.001572     0.00001   \n",
       "8        1.687885      0.755351         0.007261        0.001020     0.00001   \n",
       "9        5.650121      1.107171         0.007872        0.001410     0.00001   \n",
       "10       1.133727      0.225058         0.004721        0.000343     0.00001   \n",
       "11       3.743411      0.238099         0.004011        0.000839     0.00001   \n",
       "12       0.833095      0.078432         0.006237        0.000306    0.000001   \n",
       "13       4.737202      0.075470         0.004004        0.000193    0.000001   \n",
       "14       1.135623      0.382506         0.003929        0.000221    0.000001   \n",
       "15       3.272423      0.086265         0.005157        0.000333    0.000001   \n",
       "16       1.480208      1.164858         0.004523        0.000339    0.000001   \n",
       "17       4.773138      1.677395         0.004736        0.000940    0.000001   \n",
       "\n",
       "   param_hidden_layer_sizes param_solver  \\\n",
       "0                     (15,)        lbfgs   \n",
       "1                     (15,)          sgd   \n",
       "2                      (5,)        lbfgs   \n",
       "3                      (5,)          sgd   \n",
       "4                     (10,)        lbfgs   \n",
       "5                     (10,)          sgd   \n",
       "6                     (15,)        lbfgs   \n",
       "7                     (15,)          sgd   \n",
       "8                      (5,)        lbfgs   \n",
       "9                      (5,)          sgd   \n",
       "10                    (10,)        lbfgs   \n",
       "11                    (10,)          sgd   \n",
       "12                    (15,)        lbfgs   \n",
       "13                    (15,)          sgd   \n",
       "14                     (5,)        lbfgs   \n",
       "15                     (5,)          sgd   \n",
       "16                    (10,)        lbfgs   \n",
       "17                    (10,)          sgd   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.0001, 'hidden_layer_sizes': (15,),...           0.560000   \n",
       "1   {'alpha': 0.0001, 'hidden_layer_sizes': (15,),...           0.750000   \n",
       "2   {'alpha': 0.0001, 'hidden_layer_sizes': (5,), ...           0.558140   \n",
       "3   {'alpha': 0.0001, 'hidden_layer_sizes': (5,), ...           0.781250   \n",
       "4   {'alpha': 0.0001, 'hidden_layer_sizes': (10,),...           0.578313   \n",
       "5   {'alpha': 0.0001, 'hidden_layer_sizes': (10,),...           0.727273   \n",
       "6   {'alpha': 1e-05, 'hidden_layer_sizes': (15,), ...           0.522727   \n",
       "7   {'alpha': 1e-05, 'hidden_layer_sizes': (15,), ...           0.805556   \n",
       "8   {'alpha': 1e-05, 'hidden_layer_sizes': (5,), '...           0.580247   \n",
       "9   {'alpha': 1e-05, 'hidden_layer_sizes': (5,), '...           0.750000   \n",
       "10  {'alpha': 1e-05, 'hidden_layer_sizes': (10,), ...           0.565217   \n",
       "11  {'alpha': 1e-05, 'hidden_layer_sizes': (10,), ...           0.600000   \n",
       "12  {'alpha': 1e-06, 'hidden_layer_sizes': (15,), ...           0.590909   \n",
       "13  {'alpha': 1e-06, 'hidden_layer_sizes': (15,), ...           0.702128   \n",
       "14  {'alpha': 1e-06, 'hidden_layer_sizes': (5,), '...           0.526882   \n",
       "15  {'alpha': 1e-06, 'hidden_layer_sizes': (5,), '...           0.672727   \n",
       "16  {'alpha': 1e-06, 'hidden_layer_sizes': (10,), ...           0.587500   \n",
       "17  {'alpha': 1e-06, 'hidden_layer_sizes': (10,), ...           0.888889   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.524390           0.483871           0.518987   \n",
       "1            0.627119           0.562500           0.551724   \n",
       "2            0.609195           0.569767           0.578313   \n",
       "3            0.676471           0.555556           0.580645   \n",
       "4            0.568182           0.449438           0.540230   \n",
       "5            0.636364           0.552239           0.515152   \n",
       "6            0.573333           0.511364           0.576471   \n",
       "7            0.636364           0.607143           0.544118   \n",
       "8            0.530120           0.568182           0.530864   \n",
       "9            0.596154           0.582090           0.500000   \n",
       "10           0.586207           0.532609           0.551724   \n",
       "11           0.636364           0.551724           0.506849   \n",
       "12           0.572917           0.531915           0.554054   \n",
       "13           0.636364           0.544118           0.510204   \n",
       "14           0.571429           0.518987           0.513158   \n",
       "15           0.000000           0.633333           0.000000   \n",
       "16           0.580247           0.488095           0.566265   \n",
       "17           0.714286           0.584906           0.516129   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.523810         0.522212        0.024148               16  \n",
       "1            0.618182         0.621905        0.070574                3  \n",
       "2            0.578947         0.578873        0.016927                8  \n",
       "3            0.000000         0.518784        0.271319               17  \n",
       "4            0.563218         0.539876        0.046910               13  \n",
       "5            0.600000         0.606205        0.073224                4  \n",
       "6            0.482353         0.533250        0.036483               14  \n",
       "7            0.527273         0.624090        0.099133                2  \n",
       "8            0.505263         0.542935        0.027418               12  \n",
       "9            0.540000         0.593649        0.085128                5  \n",
       "10           0.505263         0.548204        0.027688               11  \n",
       "11           0.613636         0.581715        0.046571                7  \n",
       "12           0.540230         0.558005        0.021528                9  \n",
       "13           0.526316         0.583826        0.073566                6  \n",
       "14           0.512195         0.528530        0.022078               15  \n",
       "15           0.000000         0.261212        0.320161               18  \n",
       "16           0.539326         0.552287        0.036071               10  \n",
       "17           0.692308         0.679303        0.127166                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176853055916776"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False,  True,  True])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, clf.predict(X_test)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016355140186916"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3983644859813084"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6544772620721988"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3455227379278012"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_250_long = pd.DataFrame(data['statement'].str.len().sort_values()[:20700])\n",
    "final_data = data.merge(minus_250_long,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_labels = pd.read_csv(\"Downloads/prediction_results\")['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1        False\n",
       "2         True\n",
       "3        False\n",
       "4         True\n",
       "         ...  \n",
       "11644     True\n",
       "11645     True\n",
       "11646    False\n",
       "11647    False\n",
       "11648    False\n",
       "Name: 0, Length: 11649, dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = pd.DataFrame(X).iloc[:gpt_labels.size]\n",
    "new_X['new_col'] = gpt_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X.to_numpy(), y[:gpt_labels.size], test_size=0.33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamansinha/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,), solver='lbfgs')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317295188556566"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6096009253903991"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, clf.predict(X_test)).ravel()\n",
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39039907460960094"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6498109640831758"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3501890359168242"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
